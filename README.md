# ğŸš¨ AI Incident Response Agent

A production-ready AI agent that helps engineering teams investigate and respond to production incidents by analyzing service logs and runbook documentation using **LangGraph orchestration + Retrieval Augmented Generation (RAG)**.

---

## ğŸŒŸ Why this project exists

During incidents, engineers spend valuable time searching logs, dashboards, and runbooks to understand what went wrong.

This system acts as an **AI copilot for incident response**, helping reduce time to diagnose and improve troubleshooting accuracy.

The agent can:

â€¢ Analyze service logs and error traces  
â€¢ Retrieve relevant runbook documentation  
â€¢ Suggest likely root causes  
â€¢ Recommend next debugging steps  
â€¢ Maintain conversation memory across sessions  

---

## ğŸ—ï¸ Architecture Overview

High level workflow:

User query or logs  
â¡ï¸ LangGraph orchestration  
â¡ï¸ RAG pipeline retrieves relevant logs and runbooks from pgvector  
â¡ï¸ LLM reasoning with tools and memory  
â¡ï¸ Structured incident response  

Core stack:

â€¢ **FastAPI** for async API backend  
â€¢ **LangGraph** for agent orchestration  
â€¢ **PostgreSQL + pgvector** for vector search  
â€¢ **OpenAI models** for reasoning and embeddings  
â€¢ **Prometheus + Grafana** for monitoring  
â€¢ **Docker** for containerization  
â€¢ **AWS ready deployment**

---

## ğŸ¤– Key Features

### ğŸ” Incident Investigation Agent

â€¢ Upload logs or paste incident details  
â€¢ Semantic search across runbooks and past incidents  
â€¢ Root cause analysis suggestions  
â€¢ Recommended debugging steps  
â€¢ Conversation memory per user  

---

### ğŸ§  Retrieval Augmented Generation Pipeline

This project uses a full RAG pipeline to ground responses in real engineering knowledge.

â€¢ Log ingestion and chunking pipeline  
â€¢ Document ingestion pipeline for runbooks  
â€¢ Embedding generation using OpenAI models  
â€¢ Vector similarity search with PostgreSQL + pgvector  
â€¢ Context injection into LLM prompts for grounded reasoning

---

### âš™ï¸ Production Backend

â€¢ FastAPI async REST API  
â€¢ JWT authentication and session management  
â€¢ Rate limiting and input validation  
â€¢ Structured logging with request context  
â€¢ Streaming responses support  

---

### ğŸ“Š Observability & Evaluation

â€¢ Prometheus metrics + Grafana dashboards  
â€¢ Langfuse LLM tracing  
â€¢ Automated evaluation framework  
â€¢ JSON reports with success metrics  

---

### âš¡ Performance & Reliability

â€¢ Docker + Docker Compose setup  
â€¢ Redis caching support  
â€¢ Automatic retry logic for LLM calls  
â€¢ Async database connection pooling  

---

## ğŸ’¡ Example Use Cases

Example queries:

â€¢ â€œHere are logs from the payment service. Why is checkout failing?â€  
â€¢ â€œWe are seeing repeated 503 errors. What could be wrong?â€  
â€¢ â€œSummarize this incident and suggest next steps.â€

The agent retrieves relevant runbook sections and produces structured troubleshooting guidance.

---

## ğŸ“‚ Project Structure

```
app/
 â”œâ”€â”€ api/                # REST API endpoints (auth + chat)
 â”œâ”€â”€ core/langgraph/     # LangGraph agent workflow & tools
 â”œâ”€â”€ services/
 â”‚     â”œâ”€â”€ database.py   # PostgreSQL + pgvector integration
 â”‚     â””â”€â”€ llm.py        # LLM + embedding service
 â”œâ”€â”€ prompts/            # System prompts & RAG instructions

scripts/                 # Log + runbook ingestion pipeline (RAG indexing)
evals/                   # Evaluation framework for agent accuracy
prometheus/              # Metrics configuration
grafana/                 # Monitoring dashboards
```

---

## ğŸš€ Getting Started

### Prerequisites

â€¢ Python 3.13  
â€¢ PostgreSQL  
â€¢ Docker + Docker Compose  
â€¢ OpenAI API Key  

---

### ğŸ”§ Local Setup

Clone the repo

```
git clone https://github.com/your-username/ai-incident-response-agent.git
cd ai-incident-response-agent
```

Install dependencies

```
uv sync
```

Create environment file

```
cp .env.example .env.development
```

Add required variables

```
OPENAI_API_KEY=your_key
POSTGRES_HOST=localhost
POSTGRES_DB=incident_agent
SECRET_KEY=your_secret
```

Run locally

```
make dev
```

Swagger docs available at  
http://localhost:8000/docs

---

## ğŸ³ Run with Docker

```
make docker-build-env ENV=development
make docker-run-env ENV=development
```

Monitoring dashboards

Prometheus â†’ http://localhost:9090  
Grafana â†’ http://localhost:3000  

---

## ğŸ§ª Evaluation

Run automated evaluation

```
make eval-quick ENV=development
```

Reports generated in:

```
evals/reports/
```

Metrics include success rate and response quality.

---

## ğŸ”® Future Improvements

â€¢ Cloud log ingestion integrations  
â€¢ Slack and email alerting support  
â€¢ Larger evaluation datasets  
â€¢ Advanced multi-step agent workflows  

---

## ğŸ™Œ Acknowledgements

Built using a production FastAPI + LangGraph template and extended with a real-world incident response use case.
